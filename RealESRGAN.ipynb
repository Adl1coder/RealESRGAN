{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ahFMgoQ74mb13KqHeCX-ssuXOzQb9qru",
      "authorship_tag": "ABX9TyPTLGhhoYNHRjfZ/ZtYlDnm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adl1coder/RealESRGAN/blob/main/RealESRGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[EN]\n",
        "\n",
        "\n",
        "Real-ESRGAN (Real-Enhanced Super-Resolution Generative Adversarial Networks) is a state-of-the-art method for enhancing the resolution of images using deep learning techniques. It employs Generative Adversarial Networks (GANs) to upscale images while preserving high-quality details and textures. This technology is particularly effective for tasks like improving the quality of low-resolution images and is widely used in fields such as digital art restoration, medical imaging, and satellite imagery.\n",
        "\n",
        "[TR]\n",
        "Real-ESRGAN (Gerçek-Geliştirilmiş Süper-Çözünürlük Üretici Rakip Ağlar), derin öğrenme tekniklerini kullanarak görüntülerin çözünürlüğünü artırmak için kullanılan bir yöntemdir. Görüntüleri yüksek kaliteli detaylar ve dokularını koruyarak büyütmek için Üretici Rakip Ağlar (GAN'lar) kullanır. Bu teknoloji, düşük çözünürlüklü görüntülerin kalitesini artırma gibi görevlerde özellikle etkilidir ve dijital sanat restorasyonu, tıbbi görüntüleme ve uydu görüntüleri gibi alanlarda yaygın olarak kullanılır.\n",
        "\n",
        "Help from /kvignesh122/image-enhancement/\n"
      ],
      "metadata": {
        "id": "xA4NY-OrGxtb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k5E8zym71CFP"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import queue\n",
        "import threading\n",
        "import torch\n",
        "\n",
        "from torch.nn import functional as F\n",
        "from torch import nn as nn\n",
        "from PIL import Image\n",
        "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "from math import ceil, floor, sqrt\n",
        "from PIL import Image, ImageFilter\n",
        "from IPython.display import Image as display_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gthIYRXb1pcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_jpg(input_path, output_path):\n",
        "    with Image.open(input_path) as img:\n",
        "        img.convert(\"RGB\").save(output_path, 'JPEG')\n",
        "class RealESRGANer():\n",
        "    def __init__(self,\n",
        "                 scale,\n",
        "                 model_path,\n",
        "                 model=None,\n",
        "                 tile=0,\n",
        "                 tile_pad=10,\n",
        "                 pre_pad=10,\n",
        "                 half=False,\n",
        "                 device=None,\n",
        "                 gpu_id=None):\n",
        "        self.scale = scale\n",
        "        self.tile_size = tile\n",
        "        self.tile_pad = tile_pad\n",
        "        self.pre_pad = pre_pad\n",
        "        self.mod_scale = None\n",
        "        self.half = half\n",
        "        if gpu_id:\n",
        "            self.device = torch.device(\n",
        "                f'cuda:{gpu_id}' if torch.cuda.is_available() else 'cpu') if device is None else device\n",
        "        else:\n",
        "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') if device is None else device\n",
        "\n",
        "        loadnet = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "\n",
        "        if 'params_ema' in loadnet:\n",
        "            keyname = 'params_ema'\n",
        "        else:\n",
        "            keyname = 'params'\n",
        "        model.load_state_dict(loadnet[keyname], strict=True)\n",
        "        model.eval()\n",
        "        self.model = model.to(self.device)\n",
        "        if self.half:\n",
        "            self.model = self.model.half()\n",
        "    def pre_process(self, img):\n",
        "        \"\"\"Pre-process, such as pre-pad and mod pad, so that the images can be divisible\n",
        "        \"\"\"\n",
        "        img = torch.from_numpy(np.transpose(img, (2, 0, 1))).float()\n",
        "        self.img = img.unsqueeze(0).to(self.device)\n",
        "        if self.half:\n",
        "            self.img = self.img.half()\n",
        "        if self.pre_pad != 0:\n",
        "            self.img = F.pad(self.img, (0, self.pre_pad, 0, self.pre_pad), 'reflect')\n",
        "\n",
        "        if self.scale == 2:\n",
        "            self.mod_scale = 2\n",
        "        elif self.scale == 1:\n",
        "            self.mod_scale = 4\n",
        "        if self.mod_scale is not None:\n",
        "            self.mod_pad_h, self.mod_pad_w = 0, 0\n",
        "            _, _, h, w = self.img.size()\n",
        "            if (h % self.mod_scale != 0):\n",
        "                self.mod_pad_h = (self.mod_scale - h % self.mod_scale)\n",
        "            if (w % self.mod_scale != 0):\n",
        "                self.mod_pad_w = (self.mod_scale - w % self.mod_scale)\n",
        "            self.img = F.pad(self.img, (0, self.mod_pad_w, 0, self.mod_pad_h), 'reflect')\n",
        "    def process(self):\n",
        "        self.output = self.model(self.img)\n",
        "    def tile_process(self):\n",
        "        batch, channel, height, width = self.img.shape\n",
        "        output_height = height * self.scale\n",
        "        output_width = width * self.scale\n",
        "        output_shape = (batch, channel, output_height, output_width)\n",
        "        self.output = self.img.new_zeros(output_shape)\n",
        "        tiles_x = math.ceil(width / self.tile_size)\n",
        "        tiles_y = math.ceil(height / self.tile_size)\n",
        "        for y in range(tiles_y):\n",
        "            for x in range(tiles_x):\n",
        "                ofs_x = x * self.tile_size\n",
        "                ofs_y = y * self.tile_size\n",
        "                input_start_x = ofs_x\n",
        "                input_end_x = min(ofs_x + self.tile_size, width)\n",
        "                input_start_y = ofs_y\n",
        "                input_end_y = min(ofs_y + self.tile_size, height)\n",
        "\n",
        "                input_start_x_pad = max(input_start_x - self.tile_pad, 0)\n",
        "                input_end_x_pad = min(input_end_x + self.tile_pad, width)\n",
        "                input_start_y_pad = max(input_start_y - self.tile_pad, 0)\n",
        "                input_end_y_pad = min(input_end_y + self.tile_pad, height)\n",
        "\n",
        "                input_tile_width = input_end_x - input_start_x\n",
        "                input_tile_height = input_end_y - input_start_y\n",
        "                tile_idx = y * tiles_x + x + 1\n",
        "                input_tile = self.img[:, :, input_start_y_pad:input_end_y_pad, input_start_x_pad:input_end_x_pad]\n",
        "\n",
        "                try:\n",
        "                    with torch.no_grad():\n",
        "                        output_tile = self.model(input_tile)\n",
        "                except RuntimeError as error:\n",
        "                    print('Error', error)\n",
        "                print(f'\\tTile {tile_idx}/{tiles_x * tiles_y}')\n",
        "\n",
        "                output_start_x = input_start_x * self.scale\n",
        "                output_end_x = input_end_x * self.scale\n",
        "                output_start_y = input_start_y * self.scale\n",
        "                output_end_y = input_end_y * self.scale\n",
        "\n",
        "                output_start_x_tile = (input_start_x - input_start_x_pad) * self.scale\n",
        "                output_end_x_tile = output_start_x_tile + input_tile_width * self.scale\n",
        "                output_start_y_tile = (input_start_y - input_start_y_pad) * self.scale\n",
        "                output_end_y_tile = output_start_y_tile + input_tile_height * self.scale\n",
        "\n",
        "\n",
        "                self.output[:, :, output_start_y:output_end_y,\n",
        "                            output_start_x:output_end_x] = output_tile[:, :, output_start_y_tile:output_end_y_tile,\n",
        "                                                                       output_start_x_tile:output_end_x_tile]\n",
        "\n",
        "    def post_process(self):\n",
        "\n",
        "        if self.mod_scale is not None:\n",
        "            _, _, h, w = self.output.size()\n",
        "            self.output = self.output[:, :, 0:h - self.mod_pad_h * self.scale, 0:w - self.mod_pad_w * self.scale]\n",
        "\n",
        "        if self.pre_pad != 0:\n",
        "            _, _, h, w = self.output.size()\n",
        "            self.output = self.output[:, :, 0:h - self.pre_pad * self.scale, 0:w - self.pre_pad * self.scale]\n",
        "        return self.output\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def enhance(self, img, outscale=None, alpha_upsampler='realesrgan'):\n",
        "        h_input, w_input = img.shape[0:2]\n",
        "\n",
        "        img = img.astype(np.float32)\n",
        "        if np.max(img) > 256:  # 16-bit image\n",
        "            max_range = 65535\n",
        "            print('\\tInput is a 16-bit image')\n",
        "        else:\n",
        "            max_range = 255\n",
        "        img = img / max_range\n",
        "        if len(img.shape) == 2:\n",
        "            img_mode = 'L'\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "        elif img.shape[2] == 4:\n",
        "            img_mode = 'RGBA'\n",
        "            alpha = img[:, :, 3]\n",
        "            img = img[:, :, 0:3]\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            if alpha_upsampler == 'realesrgan':\n",
        "                alpha = cv2.cvtColor(alpha, cv2.COLOR_GRAY2RGB)\n",
        "        else:\n",
        "            img_mode = 'RGB'\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        self.pre_process(img)\n",
        "        if self.tile_size > 0:\n",
        "            self.tile_process()\n",
        "        else:\n",
        "            self.process()\n",
        "        output_img = self.post_process()\n",
        "        output_img = output_img.data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
        "        output_img = np.transpose(output_img[[2, 1, 0], :, :], (1, 2, 0))\n",
        "        if img_mode == 'L':\n",
        "            output_img = cv2.cvtColor(output_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        if img_mode == 'RGBA':\n",
        "            if alpha_upsampler == 'realesrgan':\n",
        "                self.pre_process(alpha)\n",
        "                if self.tile_size > 0:\n",
        "                    self.tile_process()\n",
        "                else:\n",
        "                    self.process()\n",
        "                output_alpha = self.post_process()\n",
        "                output_alpha = output_alpha.data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
        "                output_alpha = np.transpose(output_alpha[[2, 1, 0], :, :], (1, 2, 0))\n",
        "                output_alpha = cv2.cvtColor(output_alpha, cv2.COLOR_BGR2GRAY)\n",
        "            else:\n",
        "                h, w = alpha.shape[0:2]\n",
        "                output_alpha = cv2.resize(alpha, (w * self.scale, h * self.scale), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "            output_img = cv2.cvtColor(output_img, cv2.COLOR_BGR2BGRA)\n",
        "            output_img[:, :, 3] = output_alpha\n",
        "\n",
        "\n",
        "        if max_range == 65535:\n",
        "            output = (output_img * 65535.0).round().astype(np.uint16)\n",
        "        else:\n",
        "            output = (output_img * 255.0).round().astype(np.uint8)\n",
        "\n",
        "        if outscale is not None and outscale != float(self.scale):\n",
        "            output = cv2.resize(\n",
        "                output, (\n",
        "                    int(w_input * outscale),\n",
        "                    int(h_input * outscale),\n",
        "                ), interpolation=cv2.INTER_LANCZOS4)\n",
        "\n",
        "        return output, img_mode\n",
        "\n",
        "\n",
        "class PrefetchReader(threading.Thread):\n",
        "\n",
        "\n",
        "    def __init__(self, img_list, num_prefetch_queue):\n",
        "        super().__init__()\n",
        "        self.que = queue.Queue(num_prefetch_queue)\n",
        "        self.img_list = img_list\n",
        "\n",
        "    def run(self):\n",
        "        for img_path in self.img_list:\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
        "            self.que.put(img)\n",
        "\n",
        "        self.que.put(None)\n",
        "\n",
        "    def __next__(self):\n",
        "        next_item = self.que.get()\n",
        "        if next_item is None:\n",
        "            raise StopIteration\n",
        "        return next_item\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "class IOConsumer(threading.Thread):\n",
        "\n",
        "    def __init__(self, opt, que, qid):\n",
        "        super().__init__()\n",
        "        self._queue = que\n",
        "        self.qid = qid\n",
        "        self.opt = opt\n",
        "\n",
        "    def run(self):\n",
        "        while True:\n",
        "            msg = self._queue.get()\n",
        "            if isinstance(msg, str) and msg == 'quit':\n",
        "                break\n",
        "\n",
        "            output = msg['output']\n",
        "            save_path = msg['save_path']\n",
        "            cv2.imwrite(save_path, output)\n",
        "        print(f'IO worker {self.qid} is done.')"
      ],
      "metadata": {
        "id": "7CZ9M2m41XYI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enhance_image(input_file, layers=2, upscale=2, final_filename=\"\", enhance_faces=False):\n",
        "\n",
        "  if layers == 4:\n",
        "    # 4 layers\n",
        "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
        "    netscale = 4\n",
        "    model_file = 'realesr-general-x4v3.pth'\n",
        "  elif layers == 2:\n",
        "    # 2 layers\n",
        "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=2)\n",
        "    netscale = 2\n",
        "    model_file = 'realesr-general-x2v3.pth'\n",
        "  else:\n",
        "    print(\"Layers parameter must be either 2 or 4.\")\n",
        "    return\n",
        "\n",
        "  # Final enhanced image will be upscaled by this factor using LANCZOS4 resampling\n",
        "\n",
        "  # Input image\n",
        "  imgname, org_extension = input_file.split('.')\n",
        "  image = cv2.imread(input_file)\n",
        "  org_width, org_height = image.shape[:2]\n",
        "\n",
        "  # Convert image to JPG if need be\n",
        "  if org_extension not in [\"jpeg\", \"jpg\"]:\n",
        "      \"\"\"JPG file format reduces the file size and makes it feasable for\n",
        "      faster enhancement using the model.\n",
        "      \"\"\"\n",
        "      convert_to_jpg(input_file, f\"{imgname}.jpg\")\n",
        "      input_file = f\"{imgname}.jpg\"\n",
        "\n",
        "  # Compute tile size\n",
        "  if min(org_width, org_height) <= 800:\n",
        "    tile_size = 0\n",
        "    print(f\"Small image so batching is not necessary.\")\n",
        "  else:\n",
        "    tile_size = ceil(sqrt(min(org_width, org_height))) * 10\n",
        "  if tile_size > 500:\n",
        "    tile_size = 350\n",
        "  print(f\"Tile size being used: {tile_size}\")\n",
        "\n",
        "  # restorer\n",
        "  upsampler = RealESRGANer(\n",
        "      scale=netscale,\n",
        "      model_path=model_file,\n",
        "      model=model,\n",
        "      tile=tile_size,\n",
        "      tile_pad=2,\n",
        "      half=False,\n",
        "      strict=False # Set strict to False in the RealESRGANer constructor\n",
        "  )\n",
        "\n",
        "  # Use GFPGAN for face enhancement\n",
        "  if enhance_faces:\n",
        "    from gfpgan import GFPGANer\n",
        "    face_enhancer = GFPGANer(\n",
        "        model_path='GFPGANv1.4.pth',\n",
        "        upscale=upscale,\n",
        "        arch='clean',\n",
        "        channel_multiplier=2,\n",
        "        bg_upsampler=upsampler)\n",
        "\n",
        "  img = cv2.imread(input_file, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "  try:\n",
        "    if enhance_faces:\n",
        "      _, _, output = face_enhancer.enhance(img, has_aligned=False, only_center_face=False, paste_back=True)\n",
        "    else:\n",
        "      output, _ = upsampler.enhance(img, outscale=upscale)\n",
        "  except RuntimeError as error:\n",
        "      print('Error', error)\n",
        "      print('If you encounter CUDA out of memory, try to set --tile with a smaller number.')\n",
        "      print('Else, the file you are using may be too large.')\n",
        "  else:\n",
        "    if final_filename != \"\":\n",
        "      if not (final_filename.endswith(\".jpg\") or final_filename.endswith(\".jpeg\")):\n",
        "        print(\n",
        "          \"Your preferred final filename for the output image does not or has a wrong have a file extenstion.\"\\\n",
        "          \"Append .jpg or .jpg to your preferred filename.\"\n",
        "        )\n",
        "        return\n",
        "      save_path = final_filename\n",
        "    else:\n",
        "      save_path = f'{imgname}_out.jpg'\n",
        "\n",
        "    cv2.imwrite(save_path, output)\n",
        "\n",
        "    print(f\"Enhanced image has been saved to {save_path}.\\nClick refresh button on the left panel to get latest version of {save_path}\")\n",
        "    return save_path"
      ],
      "metadata": {
        "id": "YXZblGip26Ls"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_resolution(image):\n",
        "    return image.shape[:2]\n",
        "\n",
        "def get_noise_level(image):\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Compute the Discrete Fourier Transform (DFT)\n",
        "    f_transform = np.fft.fft2(gray)\n",
        "    f_transform_shifted = np.fft.fftshift(f_transform)\n",
        "\n",
        "    # Compute the magnitude spectrum\n",
        "    magnitude_spectrum = np.abs(f_transform_shifted)\n",
        "\n",
        "    # Calculate the noise level using the standard deviation of the magnitude spectrum\n",
        "    noise_level = np.std(np.log1p(magnitude_spectrum))\n",
        "\n",
        "    return round(noise_level, 2)\n",
        "\n",
        "def get_sharpness(image):\n",
        "    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    # Apply an edge-enhancing filter (Laplacian) and compute variance as a measure of sharpness\n",
        "    laplacian = cv2.Laplacian(cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2GRAY), cv2.CV_64F)\n",
        "    return round(laplacian.var(), 2)\n",
        "\n",
        "def get_contrast(image):\n",
        "    # Using Michelson contrast measure\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    I_max = np.max(gray)\n",
        "    I_min = np.min(gray)\n",
        "    print(I_min, I_max)\n",
        "\n",
        "    contrast = (I_max - I_min) / (I_max + I_min)\n",
        "    return round(contrast, 5)\n",
        "\n",
        "\n",
        "def get_filesize(image_file):\n",
        "  file_size = os.path.getsize(image_file)\n",
        "  return round(file_size / 1_000_000, 2)\n",
        "\n",
        "\n",
        "import time\n",
        "class Timer:\n",
        "    def __init__(self) -> None:\n",
        "        self.start = 0\n",
        "        self.end = 0\n",
        "\n",
        "    def start(self):\n",
        "        self.start = time.time()\n",
        "\n",
        "    def end(self):\n",
        "        self.end = time.time()\n",
        "        elapsed_time = self.end - self.start\n",
        "        print(f\"Elapsed Time: {elapsed_time} seconds\")\n",
        "\n",
        "\n",
        "def print_quality(image_file):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_file)\n",
        "\n",
        "    # Get image metrics\n",
        "    resolution = get_resolution(image)\n",
        "    noise_level = get_noise_level(image)\n",
        "    sharpness = get_sharpness(image)\n",
        "    try:\n",
        "      contrast = get_contrast(image)\n",
        "    except:\n",
        "      contrast = \"unknown\"\n",
        "    image_size = get_filesize(image_file)\n",
        "\n",
        "    # Output the results\n",
        "    print(f\"Resolution: {resolution} pixels\")\n",
        "    print(f\"Noise Level: {noise_level} dB\")\n",
        "    print(f\"Sharpness: {sharpness}\")\n",
        "    print(f\"Contrast: {contrast}\")\n",
        "    print(f\"Size of image: {image_size} MB\")"
      ],
      "metadata": {
        "id": "kG226tLH3G9D"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install realesrgan\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csj6U1gDFQsO",
        "outputId": "20fa793a-45f9-45e7-cc3c-c40e535a18c2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: realesrgan in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: basicsr>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from realesrgan) (1.4.2)\n",
            "Requirement already satisfied: facexlib>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from realesrgan) (0.3.0)\n",
            "Requirement already satisfied: gfpgan>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from realesrgan) (1.3.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from realesrgan) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from realesrgan) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from realesrgan) (9.4.0)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from realesrgan) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from realesrgan) (0.19.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from realesrgan) (4.66.5)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (2.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (1.0.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (1.5.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (2.32.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (0.23.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (1.13.1)\n",
            "Requirement already satisfied: tb-nightly in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (2.18.0a20240902)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from basicsr>=1.4.2->realesrgan) (0.40.2)\n",
            "Requirement already satisfied: filterpy in /usr/local/lib/python3.10/dist-packages (from facexlib>=0.2.5->realesrgan) (1.4.5)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from facexlib>=0.2.5->realesrgan) (0.60.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->realesrgan) (2024.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from filterpy->facexlib>=0.2.5->realesrgan) (3.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->realesrgan) (2.1.5)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->facexlib>=0.2.5->realesrgan) (0.43.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->realesrgan) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->realesrgan) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->realesrgan) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->basicsr>=1.4.2->realesrgan) (2024.7.4)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->realesrgan) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->realesrgan) (2024.8.24)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->realesrgan) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->basicsr>=1.4.2->realesrgan) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->realesrgan) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (71.0.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->basicsr>=1.4.2->realesrgan) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr>=1.4.2->realesrgan) (8.4.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr>=1.4.2->realesrgan) (4.2.2)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->basicsr>=1.4.2->realesrgan) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->basicsr>=1.4.2->realesrgan) (3.20.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy->facexlib>=0.2.5->realesrgan) (2.8.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3ZHFmTnGIpE",
        "outputId": "f59f2299-63ce-471b-9a37-ae56f3f1a187"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.4.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install basicsr\n",
        "!pip install facexlib\n",
        "!pip install gfpgan\n",
        "!pip install realesrgan\n",
        "\n",
        "\n",
        "import cv2\n",
        "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "from realesrgan import RealESRGAN\n",
        "from google.colab import files\n",
        "import os\n",
        "from math import ceil, sqrt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def enhance_image(input_file, layers=2, upscale=2, final_filename=\"\", enhance_faces=False):\n",
        "\n",
        "  if layers == 4:\n",
        "    # 4 layers\n",
        "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
        "    netscale = 4\n",
        "    model_file = 'realesr-general-x4v3.pth' # Changed the path to just the filename. The file must be in the same directory as the notebook\n",
        "  elif layers == 2:\n",
        "    # 2 layers\n",
        "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=2)\n",
        "    netscale = 2\n",
        "model_file = 'realesr-general-x2v3.pth' # Changed to the x2 version of the model\n"
      ],
      "metadata": {
        "id": "DgSdNo4kDCxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "Image.MAX_IMAGE_PIXELS = 933120000\n",
        "\n",
        "# Upload a file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the file name\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "print(f\"File uploaded: {filename}\")\n",
        "\n",
        "# Start timing\n",
        "t = Timer()\n",
        "t.start\n",
        "\n",
        "\n",
        "# You can edit the layers and enhance_faces parameters if you want.\n",
        "result = enhance_image(\n",
        "    input_file=filename, # DO NOT CHANGE THIS LINE\n",
        "    layers=2, # Choose either 2 or 4 as the value here.\n",
        "    upscale=1.5, # This value indicates the no of times the output image's resolution needs to enlarged from the original.\n",
        "    enhance_faces=True # Choose between 'True' or 'False' [First letter is capital!]\n",
        "  )\n",
        "\n",
        "\n",
        "t.end # End timing\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "\n",
        "# Image paths (replace these with your image paths)\n",
        "image_paths = [filename, f\"{filename.split('.')[0]}_out.jpg\"]\n",
        "\n",
        "# Load images\n",
        "images = [mpimg.imread(path) for path in image_paths]\n",
        "\n",
        "# Display images in the same row\n",
        "fig, axs = plt.subplots(1, len(images), figsize=(10, 5))  # Adjust the figsize as needed\n",
        "\n",
        "for i, (img, path) in enumerate(zip(images, image_paths)):\n",
        "    axs[i].imshow(img)\n",
        "    axs[i].axis('off')\n",
        "\n",
        "axs[0].set_title(f\"Original Image\")\n",
        "axs[1].set_title(f\"Enhanced Image\")\n",
        "\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "jO9QHy9L3IBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lD673AeY-dWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yeni Bölüm"
      ],
      "metadata": {
        "id": "KF91Y9li-bAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_quality(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGd1N1DF3MzO",
        "outputId": "2c408ee3-d229-41df-8481-a91247fcc045"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 255\n",
            "Resolution: (1280, 960) pixels\n",
            "Noise Level: 1.43 dB\n",
            "Sharpness: 193.62\n",
            "Contrast: 49.8\n",
            "Size of image: 0.57 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-f05f0e75b9d3>:33: RuntimeWarning: overflow encountered in scalar add\n",
            "  contrast = (I_max - I_min) / (I_max + I_min)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_quality(f\"{filename.split('.')[0]}_out.jpg\")"
      ],
      "metadata": {
        "id": "4amDXN3S3Utz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cf3IVUMNGpVx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}